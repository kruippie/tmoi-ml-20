{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "tick = datetime.datetime.now()\n",
    "# on colab with a GPU, running this complete notebook will take about 25 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[run in colab](https://colab.research.google.com/github/raoulg/tmoi-ml-20/blob/master/4-tuning_dnn/tuning_dnn.ipynb)\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/raoulg/tmoi-ml-20/blob/master/4-tuning_dnn/tuning_dnn.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist, mnist\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Dropout, BatchNormalization, Reshape\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to remove old logs folders if you want to run it again.\n",
    "#!rm -rf logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When running on a location without the utils.py file, download it.\n",
    "files = !ls\n",
    "if 'utils.py' not in files:\n",
    "    file = \"https://raw.githubusercontent.com/raoulg/tmoi-ml-20/master/4-tuning_dnn/utils.py\"\n",
    "    req = requests.get(file)\n",
    "    url_content = req.content\n",
    "    csv_file = open('utils.py', 'wb')\n",
    "    csv_file.write(url_content)\n",
    "    csv_file.close()\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected.\n"
     ]
    }
   ],
   "source": [
    "# install some missing libraries if running on colab\n",
    "# notify the user if GPU is off\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "if IS_COLAB:\n",
    "    !pip install keras-tuner\n",
    "    !pip install tensorflow-addons\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "We start with the MNIST. We already now from last lesson how easy (or difficult) it is to get a certain performance, so we can evaluate the impact of the different types of activations, batchnorm and activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = mnist.load_data()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should look sort of familiar by now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((6000, 28, 28), (6000,))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "255"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will need scaling\n",
    "np.max(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "We start with a baselinemodel, that is the result from the hypertuning of last lesson. Note how I put the rescaling inside the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "score = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# takes about 1min30s\n",
    "tf.random.set_seed(42) \n",
    "log_dir = \"logs/fit/\" + \"base\"\n",
    "tbcb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# this random.set_seed makes sure that the random initialization \n",
    "# of the weight is every time the same.\n",
    "# normally, you won't need that, but this makes sure \n",
    "# that the lesson has the exact same output, every time you run it.\n",
    "early_stop = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Rescaling(1./255),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "result['base'] = model.fit(X_train, y_train, epochs=7, validation_data=(X_valid, y_valid), callbacks=[early_stop, tbcb], verbose = 0)\n",
    "score['base'] = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that normally, you would set the epochs high (eg `epochs=-100`) and let the `EarlyStopping` interrupt the notebook. Because every epoch takes quite some time, I ran it once, and adjusted the runtime by reducing the amount of epochs. This just saves time when I need to rerun the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result, ymax = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring activation functions\n",
    "\n",
    "### selu\n",
    "Let's try the SELU. We need the data to be scaled by a standard scaler, and our kernel intializer should be `lecun_normal`. Note that we have to remove the rescaling inside the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_trains = scaler.fit_transform(X_train.reshape(len(X_train), -1))\n",
    "X_valids = scaler.transform(X_valid.reshape(len(X_valid), -1))\n",
    "X_tests = scaler.transform(X_test.reshape(len(X_test), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#takes about 1min15s\n",
    "tf.random.set_seed(42)\n",
    "log_dir = \"logs/fit/\" + \"selu\"\n",
    "tbcb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model = Sequential([\n",
    "    Dense(256, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    Dense(256, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    Dense(256, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "result['selu']  = model.fit(X_trains, y_train, epochs=6, validation_data=(X_valids, y_valid), callbacks=[early_stop, tbcb], verbose = 0)\n",
    "score['selu'] = model.evaluate(X_tests, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result, ymin=0, ymax = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(X_train), np.std(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not really an improvement. A problem is that the data is not really normal distributed, with a mean of 33 and a std of 78. Tweaking that might give you better results, but for now we will leave it as it is. \n",
    "### Gelu\n",
    "Let's try GELU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#takes about 1min20s\n",
    "tf.random.set_seed(42)\n",
    "log_dir = \"logs/fit/\" + \"gelu\"\n",
    "tbcb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "from tensorflow_addons.layers import GELU\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Rescaling(1./255),\n",
    "    Dense(256),\n",
    "    GELU(),\n",
    "    Dense(256),\n",
    "    GELU(),\n",
    "    Dense(256),\n",
    "    GELU(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "result['gelu']  = model.fit(X_train, y_train, epochs=6, validation_data=(X_valid, y_valid), callbacks=[early_stop, tbcb], verbose = 0)\n",
    "score['gelu'] = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_results(result, ymin=0, ymax = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(score, ymin=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's no improvement either. However, this is also slightly random. Changing the `random_seed` might change this outcome. Note, we are talking about very small differences, in the order of tenths of a percent. \n",
    "### Elu\n",
    "Now let's try `elu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#takes about 1min15s\n",
    "tf.random.set_seed(42)\n",
    "log_dir = \"logs/fit/\" + \"elu\"\n",
    "tbcb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stop = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Rescaling(1./255),\n",
    "    Dense(256, activation='elu'),\n",
    "    Dense(256, activation='elu'),\n",
    "    Dense(256, activation='elu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "result['elu'] = model.fit(X_train, y_train, epochs=6, validation_data=(X_valid, y_valid), callbacks=[early_stop, tbcb], verbose = 0)\n",
    "score['elu']=model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_results(result, ymin=0, ymax = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeakyReLU\n",
    "And a `LeakyReLU`. Note how we have to do that: no activation specified in the `Dense` layer! Note that tweaking the alpha could improve the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#takes about 1min30s\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "log_dir = \"logs/fit/\" + \"leaky\"\n",
    "tbcb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "tf.random.set_seed(42)\n",
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Rescaling(1./255),\n",
    "    Dense(256),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    Dense(256),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    Dense(256),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "result['leaky']  = model.fit(X_train, y_train, epochs=7, validation_data=(X_valid, y_valid), callbacks=[early_stop, tbcb], verbose = 0)\n",
    "score['leaky']=model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result, ymin=0, ymax = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(score, ymin=0.95, ymax=0.985)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: we can improve slightly on the baseline model, just by changing the activation function. But the effect is small, and can give a decrease too. \n",
    "\n",
    "Note that this is sensitive to stochastic influences. Initializing the weights differently might give different results. Also note how the baselinemodel is better on the validation set, than the leaky model, but on the testset the leaky model wins. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batchnorm\n",
    "Now, let's see what happens when we add a Batchnorm. First on our baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#takes about 2min30s\n",
    "tf.random.set_seed(42)\n",
    "log_dir = \"logs/fit/\" + \"batch_relu\"\n",
    "tbcb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Rescaling(1./255),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "result['batchnorm_relu'] = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), callbacks=[early_stop, tbcb], verbose = 0)\n",
    "score['batchnorm_relu']=model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result, ymin=0, ymax = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's an improvement! \n",
    "\n",
    "### Combining activations and batchnorm\n",
    "because we had reasonable results with GELU and LeakyReLU, let's try those too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# takes about 2min30s\n",
    "tf.random.set_seed(42)\n",
    "log_dir = \"logs/fit/\" + \"batch_gelu\"\n",
    "tbcb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "from tensorflow_addons.layers import GELU\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Rescaling(1./255),\n",
    "    Dense(256),\n",
    "    GELU(),\n",
    "    BatchNormalization(),\n",
    "    Dense(256),\n",
    "    GELU(),\n",
    "    BatchNormalization(),\n",
    "    Dense(256),\n",
    "    GELU(),\n",
    "    BatchNormalization(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "result['batchnorm_gelu']  = model.fit(X_train, y_train, epochs=9, validation_data=(X_valid, y_valid), callbacks=[early_stop, tbcb], verbose = 0)\n",
    "score['batchnorm_gelu'] = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result, ymin=0, ymax = 0.15, yscale='linear', subset='batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with the LeakeReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#takes about 2min30s\n",
    "tf.random.set_seed(42)\n",
    "log_dir = \"logs/fit/\" + \"batch_leak\"\n",
    "tbcb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Rescaling(1./255),\n",
    "    Dense(256),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    BatchNormalization(),\n",
    "    Dense(256),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    BatchNormalization(),\n",
    "    Dense(256),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    BatchNormalization(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "result['batchnorm_leaky']  = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), callbacks=[early_stop, tbcb], verbose = 0)\n",
    "score['batchnorm_leaky'] = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result, ymin=0, ymax = 0.15, alpha = 0.2, yscale='linear', subset='batchnorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(score, ymin=0.95, ymax=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have had different results, when running this notebook mutitple times. Often, the batchnorm improves the results. It also shows you something about the synergy between two parameters: simply switching to another activation function could decrease performance, but adding batchnormalization together with an activation could increase performance.\n",
    "\n",
    "While it might sometimes reduce the result, note that the differences for the MNIST are really small; we are talking about a few last 'hard nuts'. The problems here are dominantly in our model approach: if a user rotates a number too much, or hasnt centered it, our results get off because we look at every pixel as a feature and don't take context into account. \n",
    "\n",
    "Nevertheless, usually, adding `BatchNormalization` is a good idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "Now, let's experiment with Dropout. We start with a single dropout layer, just before the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# takes about 2min37s\n",
    "tf.random.set_seed(42)\n",
    "log_dir = \"logs/fit/\" + \"batch_rely_1drop\"\n",
    "tbcb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Rescaling(1./255),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "result['batchnorm_relu_1dropout'] = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), callbacks=[early_stop, tbcb], verbose = 0)\n",
    "score['batchnorm_relu_1dropout']=model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result, ymin=0, ymax = 0.15, yscale='linear', subset='batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add dropouts after every layer (except after the last)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# takes about 4min total\n",
    "tf.random.set_seed(42)\n",
    "log_dir = \"logs/fit/\" + \"batch_relu_3drop40\"\n",
    "tbcb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Rescaling(1./255),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "result['batchnorm_relu_3dropout40'] = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[early_stop, tbcb], verbose = 0)\n",
    "score['batchnorm_relu_3dropout40']=model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result, ymin=0, ymax = 0.15, yscale='linear', subset = 'batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might seem weird! The train goes worse, but the valid goes better! It's actually the best, so far. Note that it takes a lot more time to train, too.\n",
    "\n",
    "Let's create a forloop to test different values of the dropout, to see what that does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tf.random.set_seed(42)\n",
    "drops = [0.3, 0.2, 0.1]\n",
    "for drop in drops:\n",
    "    name = 'batchnorm_relu_3dropout{0}'.format(int(drop*100))\n",
    "    log_dir = \"logs/fit/\" + name \n",
    "    tbcb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    model = Sequential([\n",
    "        Flatten(),\n",
    "        Rescaling(1./255),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(drop),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(drop),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(drop),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "    \n",
    "    result[name] = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[early_stop, tbcb], verbose = 0)\n",
    "    score[name] = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result, ymin=0, ymax = 0.15, yscale='linear', subset = 'dropout[0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_results(result, grid=True, ymax = 0.3, subset='dropout[0-9]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result might suprise you. We can see that the training result is *worse* than the validation result with the dropout. That is something you normally don't expect! How does that make sense? Is the model underfitting, instead of overfitting? \n",
    "\n",
    "Well, actually, no. Or, it might. But it makes sense with dropout.\n",
    "\n",
    "What we are seeing, is the impact of the dropout. Because the dropout drops random units during training, the train result will underperform, but it will give a better result during validation when there are no longer drops active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(score, ymin=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With dropout, the batchnorm_relu is improved for rates of 30, 20 and 10%. We might get improvements with leaky or gelu too; try it out if you are curious!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Convolutions and Hypermodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next lesson, we will dive into the theory behind convolutions and maxpooling. For now, let's just try to add these new types of layers to see their effect.\n",
    "\n",
    "- a Conv2D layer expects (as the name suggests) **2D data**, but with an additional dimension for color / grayscale. So, every example has shape (batchsize x height x width) which does not has a channel defined. So we need to add an additional dimension, to specify that we have just one channel for color . We can do this with either reshape, or just with `Input(shape=[28,28,1])`. We will end with a **4D shape** for all data, eg (batchsize x height x width x channels)\n",
    "- We can tune the amount of filters (first argument) and the size of the kernel (second argument). In this example, I have fixated the kernelsize at 3, and set the amount of filters as a hyperparameters to be tuned by the model.\n",
    "- After a convolution, you can add a MaxPool2D layer. Again, **4D shapes** are expected (1D for batch, 2D imagedimensions with 1D for channels).\n",
    "- the amount of combinations of Conv2d and MaxPool2D is something that we will hypertune.\n",
    "- After we are finished with convolutions & pooling, we want to pass the result to our Dense layers. However, they still expect the data to have a shape (batchsize x features), so we need to **flatten the 2D shape** into a 1D feature vector.\n",
    "- For the Dense layers, we will add Batchnormalization and Dropouts. The amount of dropout is a hyperparameter to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.layers import LeakyReLU, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + \"cnn\"\n",
    "tbcb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model = Sequential([\n",
    "    Reshape((28,28,1)),\n",
    "    Rescaling(1./255),\n",
    "    Conv2D(16, (3,3), activation='relu'),\n",
    "    MaxPool2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "result['conv'] = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[early_stop, tbcb], verbose = 0)\n",
    "score['conv'] = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(score, ymin=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, while this (again) improves what we have, we run into a real problem. We just have too many options to test.\n",
    "In addition to that, they might interact. So, we could manually tune the amount of units, but maybe the optimal value is different when we toss in a Conv2D layer!\n",
    "Some goes for everything else we tested. How to get an idea of the searchspace you are looking at? Let's list a reasonable amount of values we would want to test:\n",
    "\n",
    "* activations: relu, selu, elu, gelu, leakyrelu (5)\n",
    "* alpha: leakyrelu with alpha, between 0 and 0.2 (20)\n",
    "* units: between 32 and 256, or maybe up till 1024 (~50)\n",
    "* layers: starting from 3, maybe up till 10, or even 100? (~20)\n",
    "* convlayers: filters between (3,3) and (7,7) (~4)\n",
    "* combinations of conv and maxpool layers: 1 up till 5 (~4)\n",
    "* batchnorm yes or no (2)\n",
    "* dropout between 0 and 40 (5)\n",
    "* learningrate: between $10^{-2}$ and $10^{-5}$ (20)\n",
    "\n",
    "so we get easily 5x20x50x20x4x4x2x5x20=320 million options. That is way too much to explore with a gridsearch...\n",
    "Still, it is very usefull to test things manually. This searchspace is still way too big to explore with a stochastic hyperparameter tuner, because we will sample just 10 combinations! Sure, you could increase this (and you should, in a production environment) but you still get the point: try to figure out a promising direction manually, and only then skip to the hypertuning.\n",
    "\n",
    "Another great advantage of trying things: it will give you an intuition of what it means to have 256 units, or 30, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    # input are 2D images\n",
    "    input = Input(shape = [28,28])\n",
    "    x = Rescaling(1./255)(input)\n",
    "    # but we need to add a channel for color if we want to use Conv2D layers\n",
    "    x = Reshape((28,28,1))(x)\n",
    "    \n",
    "    filters = hp.Int('filters', 16, 64, 4)\n",
    "    x = Conv2D(filters, (3,3), activation='relu')(x)\n",
    "    x = MaxPool2D((2,2))(x)\n",
    "    \n",
    "    for i in range(hp.Int('conv_layers', 0, 2)):\n",
    "        x = Conv2D(filters, (3,3), activation='relu')(x)\n",
    "        x = MaxPool2D((2,2))(x)\n",
    "        name = 'convlayer_{0}'.format(i)\n",
    "        \n",
    "    flat = Flatten()(x)\n",
    "\n",
    "    units = hp.Int('units', 128, 320, 64)\n",
    "    drops = hp.Float('drops', 0.1, 0.4)\n",
    "    leak = hp.Float('leak', 0, 0.2)\n",
    "\n",
    "    x = Dense(units)(flat)\n",
    "    x = LeakyReLU(alpha=leak)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(drops)(x)\n",
    "\n",
    "    for i in range(hp.Int('dense_layers', 1, 5)):\n",
    "        name = 'layer_{0}'.format(i)\n",
    "        x = Dense(units=units)(x)\n",
    "        x = LeakyReLU(alpha=leak)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(drops)(x)\n",
    "    \n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "    model = Model(inputs = [input], outputs = [output])\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 59s]\n",
      "val_loss: 0.046819593757390976\n",
      "\n",
      "Best val_loss So Far: 0.046819593757390976\n",
      "Total elapsed time: 00h 02m 36s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "import kerastuner as kt\n",
    "# takes about 10 minutes with max_epochs=5 and factor=3\n",
    "# takes about 5 minutes with max_epochs=3 and factor=2\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=2, # increasing this increases the total amount of trials\n",
    "    factor=3, # decreasing this will increase the amount of total trials\n",
    "    seed=10, # adding a random seed here, guarantees you get the same outcome.\n",
    "    hyperband_iterations=1, # this runs the hyperband multiple times, from scratch, when increased.\n",
    "    overwrite=True, # overwrites old runs, so you don't need to remove the folder.\n",
    "    directory='ktuner',\n",
    "    project_name='mnist'\n",
    ")\n",
    "tuner.search(X_train, y_train, validation_data = (X_valid, y_valid), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "print(best_hps.values)\n",
    "cnn_model = tuner.get_best_models()[0]\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "tf.random.set_seed(42)\n",
    "log_dir = \"logs/fit/\" + \"hyper\"\n",
    "tbcb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "result['hyper'] = cnn_model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[early_stop, tbcb], verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['hyper'] = cnn_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result, ymin=0, ymax = 0.15, subset='drop|hyper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(score, ymin=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner import HyperParameters\n",
    "hp = HyperParameters()\n",
    "# you can fix some of the values to decrease the size of the search space\n",
    "# lets fixate the units and the conv_layers, because I'm most confident about those values.\n",
    "# This way, the hyperband can focus on exploring the rest\n",
    "hp.Fixed('units', value=256)\n",
    "hp.Fixed('conv_layers', value=1)\n",
    "\n",
    "# takes about 5 minutes with max_epochs=3 and factor=2\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    hyperparameters=hp, # this overwrites the old values with the fixed values\n",
    "    tune_new_entries=True, # this allows the rest that isn't defined to be trained\n",
    "    objective='val_loss',\n",
    "    max_epochs=3, # increasing this increases the total amount of trials\n",
    "    factor=2, # decreasing this will increase the amount of total trials\n",
    "    seed=10, # adding a random seed here, guarantees you get the same outcome.\n",
    "    hyperband_iterations=1, # this runs the hyperband multiple times, from scratch, when increased.\n",
    "    overwrite=True, # overwrites old runs, so you don't need to remove the folder.\n",
    "    directory='ktuner',\n",
    "    project_name='mnist'\n",
    ")\n",
    "tuner.search(X_train, y_train, validation_data = (X_valid, y_valid), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "print(best_hps.values)\n",
    "model = tuner.get_best_models()[0]\n",
    "\n",
    "log_dir = \"logs/fit/\" + \"hyper2\"\n",
    "tbcb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "tf.random.set_seed(42)\n",
    "result['hyper2'] = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[early_stop, tbcb], verbose = 0)\n",
    "score['hyper2'] = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result, ymin=0, ymax = 0.15, subset='drop|hyper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(score, ymin=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your model\n",
    "After all this hard work and tuning, save your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mymodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('mymodel.h5')\n",
    "\n",
    "# Check its architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tock = datetime.datetime.now()\n",
    "tock - tick"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ca2ed108e0829ad954ac36f354f1cc4b518ca95c97ddb3ce5ba4e3a95bf1dea"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('tensorflow': conda)",
   "name": "python38364bittensorflowconda60937b29d62348d0bc10902efa6e00a3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}