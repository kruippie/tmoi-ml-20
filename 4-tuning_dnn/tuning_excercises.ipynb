{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[run in colab](https://colab.research.google.com/github/raoulg/tmoi-ml-20/blob/master/4-tuning_dnn/tuning_dnn.ipynb)\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/raoulg/tmoi-ml-20/blob/master/4-tuning_dnn/tuning_dnn.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist, mnist\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When running on a location without the utils.py file, download it.\n",
    "files = !ls\n",
    "if 'utils.py' not in files:\n",
    "    file = \"https://raw.githubusercontent.com/raoulg/tmoi-ml-20/master/4-tuning_dnn/utils.py\"\n",
    "    req = requests.get(file)\n",
    "    url_content = req.content\n",
    "    csv_file = open('utils.py', 'wb')\n",
    "    csv_file.write(url_content)\n",
    "    csv_file.close()\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install some missing libraries if running on colab\n",
    "# notify the user if GPU is off\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "if IS_COLAB:\n",
    "    !pip install keras-tuner\n",
    "    !pip install tensorflow-addons\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "The MNIST sort of became too easy. We get levels close to 99%, so it get's increasingly harder to see what improves or not. So we want a set that is harder. The fashion_mnist is a bit harder, but still doable with relative easy techniques. We can still train on a default laptop, while it is hard enough to have some space for tweaking and improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = fashion_mnist.load_data()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.4, random_state=42)\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels are sparse\n",
    "y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the set a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[y_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "Build a baseline deep learning model with settings you guess are simple, but good enough to give you a baseline to improve. E.g. try just one or two layers of Dense layers.\n",
    "\n",
    "Store results and scores.\n",
    "\n",
    "If you are curious about simple (non-deep learning models) You can have a look here [here](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/#) for benchmarks with simple models. Note the trainingtime, before you attempt to reproduce this with a simple model; some really take hours! Also try to sort the models by accuracy, and note the best model: an SVC with a kernel... Downside is, that it takes more than an hour to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "score = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout, Batchnorm, activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment manually with batchnorm, drops and different activations to get a sense of how they impact the model. \n",
    "Store your results in dictionaries, such that is it easy to compare (see lesson for examples). If you want to test with `Conv2D` and `MaxPool2D` layers, you can use `Reshape((28,28,1))` to get the desired 4D shape for image convolutions.\n",
    "\n",
    "Getting above 90% on the testset is actually pretty good for the fashion mnist.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs1 = X_train.reshape((60000, 28, 28, 1))\n",
    "rs1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Reshape\n",
    "x = X_train[:32]\n",
    "rs3 = Reshape((28,28,1))(x)\n",
    "rs3.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your models here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your best manual tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('manual_tune.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypertuning\n",
    "Build a hypermodel. Start with broad settings, and use `hp.Fixed` to fixate things your are fairly sure about. You should be able to get above 90% accuracy on the testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=5, # increasing the amount of epochs will increase the amount of trials\n",
    "    factor=3, # decreasing the factor will increase the amount of trials\n",
    "    seed=10, # by setting the seed, you guarantee the same outcome every time you run the hyperband\n",
    "    hyperband_iterations=1, # run the complete algorithm more than once, starting from scratch every time.\n",
    "    directory='ktuner',\n",
    "    project_name='fashion_mnist'\n",
    ")\n",
    "tuner.search(X_train, y_train, validation_data = (X_valid, y_valid), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "print(best_hps.values)\n",
    "model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "result['hyper'] = model.fit(X_train, y_train, \n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid), \n",
    "    callbacks=[early_stop],\n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['hyper']=model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(score, ymin=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('hypertune.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('hypertune.h5')\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('tensorflow': conda)",
   "name": "python38364bittensorflowconda60937b29d62348d0bc10902efa6e00a3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}